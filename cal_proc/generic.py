#! /usr/bin/env python3
# -*- coding: utf-8 -*-
r"""
Generic instrument class.
"""


import datetime, pytz
import numpy as np
import netCDF4

import pdb



def walk_dstree(ds):
    """
    Recursive Dataset group generator

    from: http://unidata.github.io/netcdf4-python/netCDF4/index.html#section2

    param ds: Dataset object
    """
    values = ds.groups.values()
    yield values
    for value in ds.groups.values():
        for children in walk_dstree(value):
            yield children


class Generic():
    """
    Minimal parent class for instrument-specific parsing and processing
    of calibration data suitable for writing to the calibration netCDF.
    """

    def __init__(self,ds):
        """

        :param ds: dataset from ingested cal_nc file
            Note that cal_nc file as been read using r+. Thus variables (?)
            and attributes cannot be appended to. Values must be read to
            a python variable, the nc key deleted, then rewritten with
            appropriate modfications.
        :type ds:  netCDF4.dataset
        :returns ds:
        """
        self.ds = ds


    def __str__(self):
        """
        Help, specifically with regards to structure of update() method if
        it exists. If update() does not exist then use docstr of processor
        class __init__()
        """

        # To print name of instance use: type(self).__name__
        import pdb

        h1 = self.__doc__

        try:
            h2 = h1 + '\n' + self.update.__doc__
        except AttributeError:
            pdb.set_trace()
            h2 = h1

        try:
            h3 = h2  + '\n' + self._add__str__()
        except AttributeError:
            pdb.set_trace()
            h3 = h2

        return h3


    def update_hist(self,update=None):
        """
        Update the global history attribute.

        The history nc attribute is a single string of comma-delineated text.

        :param update: Update for history string. If None (default) then
            auto-generate string based on today's date. If given then append
            update/s to history attribute string. Any ``<now>`` or ``<today>``
            strings are changed to today's date.
        :type update: List
        """

        t_ = datetime.datetime.now(pytz.utc).replace(microsecond=0).strftime('%Y%m%d')

        if update is None:
            # With datetime v3.6 can use timespec='seconds' to drop ms
            # Timezone aware timestamp is generated by default.
            update = '{} Auto update'.format(t_)

        elif update is 'NA':
            # This assumes that all updates have been handled in the cdl
            # file. So nothing needs to be done here.
            update = ''

        elif hasattr(update,'__iter__'):
            # If is a list of strings then join
            update = ', '.join(update[:])

        # Change any shortcuts to today's date
        update = update.replace('<today>',t_).replace('<now>',t_)

        hist_ = self.ds.history
        del(self.ds.history)
        self.ds.history = '{}, {}'.format(hist_,update)


    def update_user(self,update=None):
        """
        Update the global username attribute.

        The username nc attribute is a single string of comma-delineated text.

        :param update: Update for username string. If None (default) then
            ask user, usually given as 'username <user@email>'. If given
            then append username/s to existing attribute string.
        :type update: List
        """

        if update is None:
            # May be able to automatically generate a username but
            # ask user to be sure.
            update = input('\nEnter username <email> [Enter for cdl]: ')

        elif update is 'NA':
            # This assumes that all updates have been handed in the cdl
            # file. So nothing needs to be done here
            update = ''

        elif hasattr(update,'__iter__'):
            # If is a list of strings then join
            update = ', '.join(update[:])

        else:
            user_ = self.ds.username
            del(self.ds.username)
            self.ds.username = '{}, {}'.format(user_,update)


    def change_val(self,var,old_val,new_val):
        """
        Method to change a single variable/attribute value.

        The variable or attribute name must be given along with the old
        value, ``old_val``, that is to be change to ``new_val``. If ``old_val``
        is not found then nothing is done.

        """

        pass





    def append_datasets(self,ds,
                        force_append=['username','history'],
                        exclude=[]):
        """
        Add groups, attributes, dimensions, and variables from ds.

        Attributes of *self* shall take priority over those of the same name
        in ds, such attribute values of ds shall be ignored. The exception is
        if the attribute key is included in ``force_append``. In this case the
        resultant attribute shall be a comma-delineated combination of the
        individual attributes with that from ds being appended to that of
        *self*.

        Variables from ds are appended to the same variable in *self*. The
        variables are sorted by the unlimited dimension. Variables only in
        ds shall be added to *self*.

        If any groups, attributes, or variables in ds that are not to be
        added or appended can be specified as a list with ``exclude``.

        :param ds: netCDF dataset.
        :type ds: dataset
        :param force_append: Any attribute strings that should always be
            appended to, even if they are identical. Default is
            ['username','history'].
        :type force_append: List of root or group attributes strings.
        :param exclude: List of attribute or variable names (but not variable
            attributes) that are not to be added or appended.
        :type exclude: List of identifying strings.

        """


        def append_group(mgrp,ngrp):
            """
            Update master ds group with values from new ds group

            Either input may be a dataset, in which case the root group is
            operated on, or a group/subgroup within the dataset. This function
            does not walk down through any subsequent groups.

            param mgrp: Master dataset object which may be root or a group
            param ngrp: Dataset object the contents of which shall be added or
                appended to those in the master dataset object.
            """

            # Add any new attributes, ignore any conflicts, string append any others
            new_attrs = {k_:v_ for (k_,v_) in ngrp.__dict__.items() \
                         if k_ not in mgrp.ncattrs()}
            app_attrs = {k_:v_ for (k_,v_) in ngrp.__dict__.items() \
                         if (k_ in mgrp.ncattrs() and v_ != mgrp.getncattr(k_) and k_ in force_append)}

            mgrp.setncatts(new_attrs)

            for k_,v_ in app_attrs.items():
                if mgrp.getncattr(k_) == '':
                    app_attr = ngrp.getncattr(k_)
                else:
                    app_attr =  ', '.join([mgrp.getncattr(k_)[::],
                                           ngrp.getncattr(k_)])
                mgrp.setncattr_string(k_,app_attr)

            # Add any new dimensions
            new_dim = {d_:v_ for (d_,v_) in ngrp.dimensions.items() if d_ not in mgrp.dimensions}
            mgrp.dimensions.update(new_dim)

            # Add any new variables
            new_var = {n_:v_ for (n_,v_) in ngrp.variables.items() \
                       if n_ not in mgrp.variables}
            mgrp.variables.update(new_var)

            # Concatenate any variables along the unlimited dimension
            # that exist in master already. Do this in two steps as operating
            # directly on the dataset coordinate/s affects the dependent
            # variables immediately.
            # Note that new/changed variable attributes are not added.
            app_var = {n_:v_ for (n_,v_) in ngrp.variables.items() \
                       if all([n_ in mgrp.variables,
                               not np.array_equal(ngrp.variables[n_][:],
                                                  mgrp.variables[n_][:])])}

            mod_var = {}
            for n_,v_ in app_var.items():

                # Find unlimited dimension
                for i,d_ in enumerate(mgrp.variables[n_].dimensions):
                    if mgrp.dimensions[d_].isunlimited():
                        break

                # Convert datetime stamps to datetime then back again ensuring
                # units are those of the master group.
                # Determine if timestamp with variable name and units that
                # include 'since'. A bit flakey but hopefully ok.
                if all(['time' in n_.lower(),
                        'units' in mgrp.variables[n_].ncattrs()]) \
                   and 'since' in mgrp.variables[n_].units.lower():

                    try:
                        mcalendar = mgrp.variables[n_].calendar
                    except AttributeError:
                        mcalendar = 'standard'

                    try:
                        ncalendar = ngrp.variables[n_].calendar
                    except AttributeError:
                        ncalendar = 'standard'

                    try:
                        mtime = netCDF4.num2date(mgrp.variables[n_][:],
                                                 mgrp.variables[n_].units,
                                                 mcalendar)
                    except IndexError:
                        # num2date does not work on empty arrays
                        mtime = np.array([])

                    try:
                        ntime = netCDF4.num2date(ngrp.variables[n_][:],
                                                 ngrp.variables[n_].units,
                                                 ncalendar)
                    except IndexError:
                        # num2date does not work on empty arrays
                        ntime = np.array([])

                    atime = np.ma.concatenate((mtime,ntime),axis=i)

                    mod_var[n_] = netCDF4.date2num(atime,
                                                   mgrp.variables[n_].units,
                                                   mcalendar)

                else:

    ### TODO: Use pint to make sure any units in variables are comparable
    ###       and convert new variables to those used in master

                    mod_var[n_] = np.ma.concatenate((mgrp.variables[n_][:],
                                                     ngrp.variables[n_][:]),
                                                    axis=i)

            # Write modified variables back into master
            for n_,v_ in mod_var.items():
                mgrp.variables[n_][:] = v_


        # Determine path strings to all (sub-)groups in both datasets
        mgrps = []
        for grps in walk_dstree(self.ds):
            mgrps.extend([g_.path for g_ in grps])

        ngrps = []
        for grps in walk_dstree(ds):
            ngrps.extend([g_.path for g_ in grps])

        # Determine groups that are in the new dataset that are not in the master
        # Create an equivalent empty group in the master, group will be filled
        # by calling append_dsgroup(). Sort list by length of string so
        # create upper level groups before any sub-groups.
        for grp in sorted(set(ngrps).difference(mgrps),key=len):
            self.ds.createGroup(grp)

        # Copy any new root attributes, dimensions, and/or variables to master
        append_group(self.ds,ds)

        # Do the same for all groups and sub-groups
        for grp in ngrps:
            append_group(self.ds[grp],ds[grp])



